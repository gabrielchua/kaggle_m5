{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nmega_start = time.time()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport joblib \nimport lightgbm as lgb\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# STORE_ID_REAL = [\"CA_1\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"store_list = ['TX_2', 'TX_3', 'WI_1', 'WI_2', 'WI_3']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv(\"/kaggle/input/m5-forecasting-accuracy/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cal = pd.read_csv(\"/kaggle/input/m5-processeddata/calendar_factorized.csv\")\ncal = cal.drop(['date', 'weekday'], axis = 1)\ncal['d'] = cal['d'].str.replace(\"d_\", \"\").astype(np.int16)\ncal = cal[cal['d'] > 1913]\ncal.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prices = pd.read_csv(\"/kaggle/input/m5-processeddata/sell_prices_factorized.csv\")\nprices = prices[prices['wm_yr_wk'].isin(cal['wm_yr_wk'].unique())]\nprices.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = cal.merge(prices, on = ['wm_yr_wk'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = test.drop(['wm_yr_wk'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in test.columns:\n    column = test[i]\n    if column.dtype == int:\n        if np.max(column) > 127:\n            test[i] = test[i].astype(np.int16)\n        else:\n            test[i] = test[i].astype(np.int8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# SANITY CHECK\ntest.shape[0] == (submission.shape[0] * (submission.shape[1] - 1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ------------------------------------------------------------------------------------------------","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"items = pd.read_csv(\"/kaggle/input/m5-processeddata/sales_train_validation_factorized.csv\", usecols = [1, 2, 3])\nitems = pd.concat([items['item_id'], \n                   pd.get_dummies(items['dept_id'], prefix = \"DEPT\"),\n                   pd.get_dummies(items['cat_id'], prefix = \"CAT\")],\n                  axis = 1)\n\nitems = items.drop_duplicates()\nitems.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = test.merge(items, on = ['item_id'])\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in test.columns:\n    column = test[i]\n    if column.dtype == int:\n        if np.max(column) > 127:\n            test[i] = test[i].astype(np.int16)\n        else:\n            test[i] = test[i].astype(np.int8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# SANITY CHECK\ntest.shape[0] == (submission.shape[0] * (submission.shape[1] - 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['d_sin_year'] = np.sin(2*np.pi*test['d']/365)\ntest['d_cos_year'] = np.cos(2*np.pi*test['d']/365)\ntest['d_sin_dow'] = np.sin(2*np.pi*test['d']/7)\ntest['d_cos_dow'] = np.cos(2*np.pi*test['d']/7)\ntest['d_sin_month'] = np.sin(2*np.pi*test['d']/28)\ntest['d_cos_month'] = np.cos(2*np.pi*test['d']/28)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\ndel items, prices, cal\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\nwith open('/kaggle/input/m5-processeddata/item_id_dict.json') as json_file:\n    item_dict = json.load(json_file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['id'] = submission.id.str.replace(\"_validation\", \"\").str.replace(\"_evaluation\", \"\")\nsubmission['store_id'] = submission['id'].str[-4:]\nsubmission['item_id'] = submission['id'].str[:-5]\nsubmission['item_id'] = submission['item_id'].map(item_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit_df_dict = dict()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start_time1 = time.time()\n\nfor i in store_list: \n    \n    state = i.lower()[:2]\n    \n    dummy = pd.read_feather(\"/kaggle/input/m5-dataextracttransform-partb-{}/{}_v2.feather\".format(state, i))\n    dummy = dummy.sort_values(['item_id', 'd'])\n    dummy = dummy.groupby('item_id').tail(57)\n    \n    for j in dummy.columns:\n        column = dummy[j]\n        if column.dtype == int:\n            if np.max(column) > 127:\n                dummy[j] = dummy[j].astype(np.int16)\n            else:\n                dummy[j] = dummy[j].astype(np.int8)\n        \n    test_temp = test[test['store_id'] == i]\n    \n    store_id_lower = \"{}\".format(i).replace(\"_\",\"\").lower()\n    \n    estimator = joblib.load(\"/kaggle/input/m5-train-{}/{}_v9.pkl\".format(store_id_lower, i))\n    \n    add_to_test = list(set(dummy.columns) - set(test_temp.columns))\n    extra_test = list(set(test_temp.columns) - set(dummy.columns))\n                \n    test_temp = test_temp.drop(extra_test, axis = 1)\n    \n    for j in add_to_test:\n        test_temp[j] = 0\n                \n    test_temp = pd.concat([dummy, test_temp[dummy.columns]], axis = 0)\n    \n    test_temp = test_temp.sort_values(['item_id', 'd'])\n\n    # overwrite_col = ['item_id', 'd', 'label', 'avg2', 'avg3', 'avg5', 'avg7', 'avg14', 'avg20','avg28','avg45','avg56']\n    \n    for j in range(1, 57):\n        \n        if j < 29:\n\n            # start_time = time.time()\n            # \n            rel_rows = (test_temp['d'] >= (1913-56) + j) & (test_temp['d'] <= 1913 + j)\n            rel_rows2 = test_temp['d'] == 1913 + j\n            #         \n            # test_temp.loc[rel_rows2, 'avg2'] = test_temp[rel_rows].groupby('item_id')[['label']].rolling(2).mean().groupby('item_id').shift(1).groupby('item_id').tail(1).values\n            # test_temp.loc[rel_rows2, 'avg3'] = test_temp[rel_rows].groupby('item_id')[['label']].rolling(3).mean().groupby('item_id').shift(1).groupby('item_id').tail(1).values\n            # test_temp.loc[rel_rows2, 'avg5'] = test_temp[rel_rows].groupby('item_id')[['label']].rolling(5).mean().groupby('item_id').shift(1).groupby('item_id').tail(1).values\n            # test_temp.loc[rel_rows2, 'avg7'] = test_temp[rel_rows].groupby('item_id')[['label']].rolling(7).mean().groupby('item_id').shift(1).groupby('item_id').tail(1).values\n            # test_temp.loc[rel_rows2, 'avg14'] = test_temp[rel_rows].groupby('item_id')[['label']].rolling(14).mean().groupby('item_id').shift(1).groupby('item_id').tail(1).values\n            # test_temp.loc[rel_rows2, 'avg20'] = test_temp[rel_rows].groupby('item_id')[['label']].rolling(20).mean().groupby('item_id').shift(1).groupby('item_id').tail(1).values\n            # test_temp.loc[rel_rows2, 'avg28'] = test_temp[rel_rows].groupby('item_id')[['label']].rolling(28).mean().groupby('item_id').shift(1).groupby('item_id').tail(1).values\n            # test_temp.loc[rel_rows2, 'avg35'] = test_temp[rel_rows].groupby('item_id')[['label']].rolling(35).mean().groupby('item_id').shift(1).groupby('item_id').tail(1).values\n            # test_temp.loc[rel_rows2, 'avg45'] = test_temp[rel_rows].groupby('item_id')[['label']].rolling(45).mean().groupby('item_id').shift(1).groupby('item_id').tail(1).values\n            # test_temp.loc[rel_rows2, 'avg56'] = test_temp[rel_rows].groupby('item_id')[['label']].rolling(56).mean().groupby('item_id').shift(1).groupby('item_id').tail(1).values\n    # \n            # test_temp.loc[rel_rows2, 'std2'] = test_temp[rel_rows].groupby('item_id')[['label']].rolling(2).std().groupby('item_id').shift(1).groupby('item_id').tail(1).values\n            # test_temp.loc[rel_rows2, 'std3'] = test_temp[rel_rows].groupby('item_id')[['label']].rolling(3).std().groupby('item_id').shift(1).groupby('item_id').tail(1).values\n            # test_temp.loc[rel_rows2, 'std5'] = test_temp[rel_rows].groupby('item_id')[['label']].rolling(5).std().groupby('item_id').shift(1).groupby('item_id').tail(1).values\n            # test_temp.loc[rel_rows2, 'std7'] = test_temp[rel_rows].groupby('item_id')[['label']].rolling(7).std().groupby('item_id').shift(1).groupby('item_id').tail(1).values\n            # test_temp.loc[rel_rows2, 'std14'] = test_temp[rel_rows].groupby('item_id')[['label']].rolling(14).std().groupby('item_id').shift(1).groupby('item_id').tail(1).values\n            # test_temp.loc[rel_rows2, 'std20'] = test_temp[rel_rows].groupby('item_id')[['label']].rolling(20).std().groupby('item_id').shift(1).groupby('item_id').tail(1).values\n            # test_temp.loc[rel_rows2, 'std28'] = test_temp[rel_rows].groupby('item_id')[['label']].rolling(28).std().groupby('item_id').shift(1).groupby('item_id').tail(1).values\n            # test_temp.loc[rel_rows2, 'std35'] = test_temp[rel_rows].groupby('item_id')[['label']].rolling(35).std().groupby('item_id').shift(1).groupby('item_id').tail(1).values\n            # test_temp.loc[rel_rows2, 'std45'] = test_temp[rel_rows].groupby('item_id')[['label']].rolling(45).std().groupby('item_id').shift(1).groupby('item_id').tail(1).values\n            # test_temp.loc[rel_rows2, 'std56'] = test_temp[rel_rows].groupby('item_id')[['label']].rolling(56).std().groupby('item_id').shift(1).groupby('item_id').tail(1).values\n    # \n            # test_temp.loc[rel_rows2, 'zero_avg3'] = test_temp.loc[rel_rows2, 'zero_avg3'].fillna(method = 'ffill').fillna(0)\n            # test_temp.loc[rel_rows2, 'zero_avg7'] = test_temp.loc[rel_rows2, 'zero_avg7'].fillna(method = 'ffill').fillna(0)\n            # test_temp.loc[rel_rows2, 'zero_avg14'] = test_temp.loc[rel_rows2, 'zero_avg14'].fillna(method = 'ffill').fillna(0)\n            # test_temp.loc[rel_rows2, 'zero_avg28'] = test_temp.loc[rel_rows2, 'zero_avg28'].fillna(method = 'ffill').fillna(0)\n        \n            test_temp.loc[rel_rows2, 'label'] = estimator.predict(test_temp[rel_rows2].drop('label', axis = 1))\n            \n            #total_time = time.time() - start_time\n            #print(i, j, total_time)\n    \n    test_temp['pred'] = test_temp['label']\n    \n    submission_1 = submission.iloc[:30490, :]\n    submission_2 = submission.iloc[30490:, :]\n    \n    test_temp = test_temp[['item_id', 'd', 'pred']]\n    \n    test_temp_1 = test_temp[(test_temp['d'] >= 1914) & (test_temp['d'] < (1914 + 28))]\n    test_temp_1 = test_temp_1.pivot(index='item_id',columns='d')\n    submission_1 = submission_1[submission_1['store_id'] == i]\n    \n    submission_1.iloc[:, 1:-2] = test_temp_1.values\n    \n    test_temp_2 = test_temp[(test_temp['d'] >= (1914 + 28)) & (test_temp['d'] <= (1914 + 56))]\n    test_temp_2 = test_temp_2.pivot(index='item_id',columns='d')\n    submission_2 = submission_2[submission_2['store_id'] == i]\n    \n    \n    submission_2.iloc[:, 1:-2] = test_temp_2.values\n    \n    submit_df = pd.concat([submission_1, submission_2], axis = 0).drop(['store_id', 'item_id'], axis = 1)\n    \n    submit_df.iloc[:3049,0] = submit_df.iloc[:3049,0] + \"_validation\"\n    submit_df.iloc[3049:,0] = submit_df.iloc[3049:,0] + \"_evaluation\"\n    \n    del test_temp, test_temp_1, test_temp_2, submission_1, submission_2, dummy\n    gc.collect()\n    \n    submit_df_dict[i] = submit_df\n    # submit_df.to_csv(\"submit_{}.csv\".format(i))\n\n#print(time.time() - start_time1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission2 = submit_df_dict['TX_2']\n\nfor i in ['TX_3', 'WI_1', 'WI_2', 'WI_3']:\n\n    submission2 = pd.concat([submission2, submit_df_dict[i]], axis = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv(\"/kaggle/input/m5-forecasting-accuracy/sample_submission.csv\")\nsubmission = submission[['id']].merge(submission2, on = 'id', how = 'left')\nsubmission = submission.fillna(0)\nsubmission.to_csv(\"submission_B.csv\", index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(time.time() - mega_start)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}