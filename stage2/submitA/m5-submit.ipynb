{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":["import time\n","mega_start = time.time()"],"execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import joblib \n","import lightgbm as lgb\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["STORE_ID_REAL = [\"CA_1\"]"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["store_list = ['CA_4', 'CA_2', 'CA_3', 'CA_1', 'TX_1']\n","\n","#'TX_2', 'TX_3', 'WI_1', 'WI_2', 'WI_3']"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["submission = pd.read_csv(\"/kaggle/input/m5-forecasting-accuracy/sample_submission.csv\")"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["cal = pd.read_csv(\"/kaggle/input/m5-processeddata/calendar_factorized.csv\")\n","cal = cal.drop(['date', 'weekday'], axis = 1)\n","cal['d'] = cal['d'].str.replace(\"d_\", \"\").astype(np.int16)\n","cal = cal[cal['d'] > 1913]\n","cal.head()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["prices = pd.read_csv(\"/kaggle/input/m5-processeddata/sell_prices_factorized.csv\")\n","prices = prices[prices['wm_yr_wk'].isin(cal['wm_yr_wk'].unique())]\n","prices.head()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["test = cal.merge(prices, on = ['wm_yr_wk'])"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["test = test.drop(['wm_yr_wk'], axis = 1)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["for i in test.columns:\n","    column = test[i]\n","    if column.dtype == int:\n","        if np.max(column) > 127:\n","            test[i] = test[i].astype(np.int16)\n","        else:\n","            test[i] = test[i].astype(np.int8)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# SANITY CHECK\n","test.shape[0] == (submission.shape[0] * (submission.shape[1] - 1))"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["# ------------------------------------------------------------------------------------------------"]},{"metadata":{"trusted":true},"cell_type":"code","source":["items = pd.read_csv(\"/kaggle/input/m5-processeddata/sales_train_validation_factorized.csv\", usecols = [1, 2, 3])\n","items = pd.concat([items['item_id'], \n","                   pd.get_dummies(items['dept_id'], prefix = \"DEPT\"),\n","                   pd.get_dummies(items['cat_id'], prefix = \"CAT\")],\n","                  axis = 1)\n","\n","items = items.drop_duplicates()\n","items.head()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["test = test.merge(items, on = ['item_id'])\n","test.head()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["for i in test.columns:\n","    column = test[i]\n","    if column.dtype == int:\n","        if np.max(column) > 127:\n","            test[i] = test[i].astype(np.int16)\n","        else:\n","            test[i] = test[i].astype(np.int8)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# SANITY CHECK\n","test.shape[0] == (submission.shape[0] * (submission.shape[1] - 1))"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["test['d_sin_year'] = np.sin(2*np.pi*test['d']/365)\n","test['d_cos_year'] = np.cos(2*np.pi*test['d']/365)\n","test['d_sin_dow'] = np.sin(2*np.pi*test['d']/7)\n","test['d_cos_dow'] = np.cos(2*np.pi*test['d']/7)\n","test['d_sin_month'] = np.sin(2*np.pi*test['d']/28)\n","test['d_cos_month'] = np.cos(2*np.pi*test['d']/28)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["import gc\n","del items, prices, cal\n","gc.collect()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["import json\n","with open('/kaggle/input/m5-processeddata/item_id_dict.json') as json_file:\n","    item_dict = json.load(json_file)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["submission['id'] = submission.id.str.replace(\"_validation\", \"\").str.replace(\"_evaluation\", \"\")\n","submission['store_id'] = submission['id'].str[-4:]\n","submission['item_id'] = submission['id'].str[:-5]\n","submission['item_id'] = submission['item_id'].map(item_dict)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["import time"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["submit_df_dict = dict()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":[],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["start_time1 = time.time()\n","\n","for i in store_list: \n","    \n","    state = i.lower()[:2]\n","    \n","    dummy = pd.read_feather(\"/kaggle/input/m5-dataextracttransform-partb-{}/{}_v2.feather\".format(state, i))\n","    dummy = dummy.sort_values(['item_id', 'd'])\n","    dummy = dummy.groupby('item_id').tail(57)\n","    \n","    for j in dummy.columns:\n","        column = dummy[j]\n","        if column.dtype == int:\n","            if np.max(column) > 127:\n","                dummy[j] = dummy[j].astype(np.int16)\n","            else:\n","                dummy[j] = dummy[j].astype(np.int8)\n","        \n","    test_temp = test[test['store_id'] == i]\n","    \n","    store_id_lower = \"{}\".format(i).replace(\"_\",\"\").lower()\n","    \n","    estimator = joblib.load(\"/kaggle/input/m5-train-{}/{}_v9.pkl\".format(store_id_lower, i))\n","    \n","    add_to_test = list(set(dummy.columns) - set(test_temp.columns))\n","    extra_test = list(set(test_temp.columns) - set(dummy.columns))\n","                \n","    test_temp = test_temp.drop(extra_test, axis = 1)\n","    \n","    for j in add_to_test:\n","        test_temp[j] = 0\n","                \n","    test_temp = pd.concat([dummy, test_temp[dummy.columns]], axis = 0)\n","    \n","    test_temp = test_temp.sort_values(['item_id', 'd'])\n","\n","    # overwrite_col = ['item_id', 'd', 'label', 'avg2', 'avg3', 'avg5', 'avg7', 'avg14', 'avg20','avg28','avg45','avg56']\n","    \n","    for j in range(1, 57):\n","        \n","        if j < 29:\n","\n","            # start_time = time.time()\n","            # \n","            rel_rows = (test_temp['d'] >= (1913-56) + j) & (test_temp['d'] <= 1913 + j)\n","            rel_rows2 = test_temp['d'] == 1913 + j\n","            #         \n","            test_temp.loc[rel_rows2, 'avg2'] = test_temp[rel_rows].groupby('item_id')[['label']].rolling(2).mean().groupby('item_id').shift(1).groupby('item_id').tail(1).values\n","            test_temp.loc[rel_rows2, 'avg3'] = test_temp[rel_rows].groupby('item_id')[['label']].rolling(3).mean().groupby('item_id').shift(1).groupby('item_id').tail(1).values\n","            test_temp.loc[rel_rows2, 'avg5'] = test_temp[rel_rows].groupby('item_id')[['label']].rolling(5).mean().groupby('item_id').shift(1).groupby('item_id').tail(1).values\n","            test_temp.loc[rel_rows2, 'avg7'] = test_temp[rel_rows].groupby('item_id')[['label']].rolling(7).mean().groupby('item_id').shift(1).groupby('item_id').tail(1).values\n","            test_temp.loc[rel_rows2, 'avg14'] = test_temp[rel_rows].groupby('item_id')[['label']].rolling(14).mean().groupby('item_id').shift(1).groupby('item_id').tail(1).values\n","            test_temp.loc[rel_rows2, 'avg20'] = test_temp[rel_rows].groupby('item_id')[['label']].rolling(20).mean().groupby('item_id').shift(1).groupby('item_id').tail(1).values\n","            test_temp.loc[rel_rows2, 'avg28'] = test_temp[rel_rows].groupby('item_id')[['label']].rolling(28).mean().groupby('item_id').shift(1).groupby('item_id').tail(1).values\n","            test_temp.loc[rel_rows2, 'avg35'] = test_temp[rel_rows].groupby('item_id')[['label']].rolling(35).mean().groupby('item_id').shift(1).groupby('item_id').tail(1).values\n","            test_temp.loc[rel_rows2, 'avg45'] = test_temp[rel_rows].groupby('item_id')[['label']].rolling(45).mean().groupby('item_id').shift(1).groupby('item_id').tail(1).values\n","            test_temp.loc[rel_rows2, 'avg56'] = test_temp[rel_rows].groupby('item_id')[['label']].rolling(56).mean().groupby('item_id').shift(1).groupby('item_id').tail(1).values\n","            test_temp.loc[rel_rows2, 'avg112'] = test_temp[rel_rows].groupby('item_id')[['label']].rolling(112).mean().groupby('item_id').shift(1).groupby('item_id').tail(1).values\n","            test_temp.loc[rel_rows2, 'avg156'] = test_temp[rel_rows].groupby('item_id')[['label']].rolling(156).mean().groupby('item_id').shift(1).groupby('item_id').tail(1).values\n","\n","            # test_temp.loc[rel_rows2, 'std2'] = test_temp[rel_rows].groupby('item_id')[['label']].rolling(2).std().groupby('item_id').shift(1).groupby('item_id').tail(1).values\n","            # test_temp.loc[rel_rows2, 'std3'] = test_temp[rel_rows].groupby('item_id')[['label']].rolling(3).std().groupby('item_id').shift(1).groupby('item_id').tail(1).values\n","            # test_temp.loc[rel_rows2, 'std5'] = test_temp[rel_rows].groupby('item_id')[['label']].rolling(5).std().groupby('item_id').shift(1).groupby('item_id').tail(1).values\n","            # test_temp.loc[rel_rows2, 'std7'] = test_temp[rel_rows].groupby('item_id')[['label']].rolling(7).std().groupby('item_id').shift(1).groupby('item_id').tail(1).values\n","            # test_temp.loc[rel_rows2, 'std14'] = test_temp[rel_rows].groupby('item_id')[['label']].rolling(14).std().groupby('item_id').shift(1).groupby('item_id').tail(1).values\n","            # test_temp.loc[rel_rows2, 'std20'] = test_temp[rel_rows].groupby('item_id')[['label']].rolling(20).std().groupby('item_id').shift(1).groupby('item_id').tail(1).values\n","            # test_temp.loc[rel_rows2, 'std28'] = test_temp[rel_rows].groupby('item_id')[['label']].rolling(28).std().groupby('item_id').shift(1).groupby('item_id').tail(1).values\n","            # test_temp.loc[rel_rows2, 'std35'] = test_temp[rel_rows].groupby('item_id')[['label']].rolling(35).std().groupby('item_id').shift(1).groupby('item_id').tail(1).values\n","            # test_temp.loc[rel_rows2, 'std45'] = test_temp[rel_rows].groupby('item_id')[['label']].rolling(45).std().groupby('item_id').shift(1).groupby('item_id').tail(1).values\n","            # test_temp.loc[rel_rows2, 'std56'] = test_temp[rel_rows].groupby('item_id')[['label']].rolling(56).std().groupby('item_id').shift(1).groupby('item_id').tail(1).values\n","    # \n","            # test_temp.loc[rel_rows2, 'zero_avg3'] = test_temp.loc[rel_rows2, 'zero_avg3'].fillna(method = 'ffill').fillna(0)\n","            # test_temp.loc[rel_rows2, 'zero_avg7'] = test_temp.loc[rel_rows2, 'zero_avg7'].fillna(method = 'ffill').fillna(0)\n","            # test_temp.loc[rel_rows2, 'zero_avg14'] = test_temp.loc[rel_rows2, 'zero_avg14'].fillna(method = 'ffill').fillna(0)\n","            # test_temp.loc[rel_rows2, 'zero_avg28'] = test_temp.loc[rel_rows2, 'zero_avg28'].fillna(method = 'ffill').fillna(0)\n","        \n","            test_temp.loc[rel_rows2, 'label'] = estimator.predict(test_temp[rel_rows2].drop('label', axis = 1))\n","            \n","            #total_time = time.time() - start_time\n","            #print(i, j, total_time)\n","    \n","    test_temp['pred'] = test_temp['label']\n","    \n","    submission_1 = submission.iloc[:30490, :]\n","    submission_2 = submission.iloc[30490:, :]\n","    \n","    test_temp = test_temp[['item_id', 'd', 'pred']]\n","    \n","    test_temp_1 = test_temp[(test_temp['d'] >= 1914) & (test_temp['d'] < (1914 + 28))]\n","    test_temp_1 = test_temp_1.pivot(index='item_id',columns='d')\n","    submission_1 = submission_1[submission_1['store_id'] == i]\n","    \n","    submission_1.iloc[:, 1:-2] = test_temp_1.values\n","    \n","    test_temp_2 = test_temp[(test_temp['d'] >= (1914 + 28)) & (test_temp['d'] <= (1914 + 56))]\n","    test_temp_2 = test_temp_2.pivot(index='item_id',columns='d')\n","    submission_2 = submission_2[submission_2['store_id'] == i]\n","    \n","    \n","    submission_2.iloc[:, 1:-2] = test_temp_2.values\n","    \n","    submit_df = pd.concat([submission_1, submission_2], axis = 0).drop(['store_id', 'item_id'], axis = 1)\n","    \n","    submit_df.iloc[:3049,0] = submit_df.iloc[:3049,0] + \"_validation\"\n","    submit_df.iloc[3049:,0] = submit_df.iloc[3049:,0] + \"_evaluation\"\n","    \n","    del test_temp, test_temp_1, test_temp_2, submission_1, submission_2, dummy\n","    gc.collect()\n","    \n","    submit_df_dict[i] = submit_df\n","    # submit_df.to_csv(\"submit_{}.csv\".format(i))\n","\n","#print(time.time() - start_time1)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["submission2 = submit_df_dict['CA_1']\n","\n","for i in ['CA_2', 'CA_3', 'CA_4', 'TX_1']:\n","\n","# ['TX_2', 'TX_3', 'WI_1', 'WI_2', 'WI_3']\n","\n","    submission2 = pd.concat([submission2, submit_df_dict[i]], axis = 0)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["submission = pd.read_csv(\"/kaggle/input/m5-forecasting-accuracy/sample_submission.csv\")\n","submission = submission[['id']].merge(submission2, on = 'id', how = 'left')\n","submission = submission.fillna(0)\n","submission.to_csv(\"submission_A.csv\", index = False)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["print(time.time() - mega_start)"],"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}